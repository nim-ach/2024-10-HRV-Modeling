
# Prepare workspace -------------------------------------------------------

## Load libraries
library(data.table)
library(ggplot2)
library(brms)

## Main equation
RRi_model <- function(t, alpha, beta, c, lambda, phi, tau, delta) {
  alpha +
    (beta / (1 + exp(lambda * (t - tau)))) +
    ((-beta * c) / (1 + exp(phi * (t - tau - delta))))
}

## Simulating some data
n_id <- 5
n_time <- 100

set.seed(1234)
sim_data <- within(
  data = data.table(), 
  expr = {
    alpha = rep(runif(n_id, 800, 1000), each = n_time)
    beta = rep(runif(n_id, -500, -300), each = n_time)
    c = rep(runif(n_id, .7, 1.1), each = n_time)
    lambda = rep(runif(n_id, log(1-.9), log(1-.7)), each = n_time)
    phi = rep(runif(n_id, log(1-.7), log(1-.5)), each = n_time)
    tau = rep(runif(n_id, 3, 7), each = n_time)
    delta = rep(runif(n_id, 1, 3), each = n_time)
    time = rep(x = seq(0, 20, length.out = n_time), times = n_id)
    rri_true = RRi_model(time, alpha, beta, c, lambda, phi, tau, delta)
    rri_hat = rri_true + brms::rstudent_t(n_id * n_time, df = 5, sigma = 20)
    id = rep(1:n_id, each = n_time)
  }
)

## Plot the simulated data
ggplot(sim_data, aes(time, rri_true, group = as.factor(id))) +
  facet_grid(~ id) +
  geom_line() +
  geom_line(aes(y = rri_hat)) +
  theme_linedraw()


# Simple model, no priors -------------------------------------------------

brm_model <- bf(
  formula = rri_hat ~ alpha +
    (beta / (1 + exp(lambda * (time - tau)))) +
    ((-beta * c) / (1 + exp(phi * (time - tau - delta)))),
  alpha + beta + c + lambda + phi + tau + delta ~ 1,
  nl = TRUE
)

m_1 <- brm(
  formula = brm_model,
  data = sim_data,
  family = gaussian(),
  cores = 4, chains = 4
)

## Time running: 229.443 seconds (Total)

fixef(m_1) 
#>                    Estimate  Est.Error       Q2.5        Q97.5
#> alpha_Intercept  -7405.8847 10257.0806 -34752.421   4963.65351
#> beta_Intercept     189.3855  1147.3935  -3223.571   2294.16348
#> c_Intercept       -844.8708  1722.8726  -5247.168    351.42688   # Total nonsense... Clearly I need to
#> lambda_Intercept -6578.3597 11836.4096 -30895.989     40.85204   # specify some constrains on some of
#> phi_Intercept     2940.8578 10035.7974 -14610.336  28974.64706   # (if not all) model parameters...
#> tau_Intercept     -187.3060   409.9928  -1580.806     12.01546
#> delta_Intercept  38351.1076 67815.8343  -8487.410 263154.45191


# Model 2, adding some priors ---------------------------------------------

m_priors <- 
  c(
    prior(normal(850, 50), nlpar = alpha, lb = 0),
    prior(normal(-400, 50), nlpar = beta, ub = 0),
    prior(normal(0.8, 0.2), nlpar = c, lb = 0),
    prior(normal(-2, 1), nlpar = lambda, ub = 0),
    prior(normal(-2, 1), nlpar = phi, ub = 0),
    prior(normal(5, 0.5), nlpar = tau, lb = 0),
    prior(normal(5, 0.5), nlpar = delta, lb = 0),
    prior(student_t(3, 0, 50), class = sigma, lb = 0)
  )

m_2 <- update(m_1, prior = m_priors) ## New model run, now with some informative priors

## Time running: 7.627 seconds (Total)

fixef(m_2)
#>                      Estimate   Est.Error         Q2.5        Q97.5
#> alpha_Intercept   929.9782636 15.25232370  905.9209904  964.8123367
#> beta_Intercept   -245.0123622 38.15050511 -329.5095092 -180.4549810
#> c_Intercept         0.7968700  0.04857778    0.7006231    0.8907484     ## Now we are talking!
#> lambda_Intercept   -0.8000126  0.22420478   -1.3149680   -0.4629823
#> phi_Intercept      -1.3605681  0.33058631   -2.1358631   -0.8540782
#> tau_Intercept       5.1953253  0.27215999    4.6543145    5.7300782
#> delta_Intercept     3.9906197  0.39134764    3.2112384    4.7445254

conditional_effects(m_2) ## Plot looks good!

pp_check(m_2, ndraws = 100) ## Posterior predictive checks seems fine...

## Pairs plot to check between correlations
bayesplot::mcmc_pairs(x = m_2, 
                      regex_pars = "^b_", 
                      off_diag_fun = "hex")

## Seems to be high correlation among some parameters

as_draws_df(m_2, variable = "^b_", regex = TRUE) |> 
  correlation::correlation(method = "spearman") |> 
  subset(abs(rho) > .5)
## There seems to be high correlation (rho > .5) in:
#> b_alpha_Intercept |   b_beta_Intercept | -0.75 | [-0.76, -0.73] | 1.86e+10 | < .001***
#> b_alpha_Intercept |      b_c_Intercept | -0.78 | [-0.79, -0.77] | 1.90e+10 | < .001***
#> b_alpha_Intercept | b_lambda_Intercept |  0.83 | [ 0.82,  0.84] | 1.79e+09 | < .001***
#> b_beta_Intercept  | b_lambda_Intercept | -0.77 | [-0.78, -0.76] | 1.89e+10 | < .001***
#> b_c_Intercept     | b_lambda_Intercept | -0.59 | [-0.61, -0.57] | 1.69e+10 | < .001***
#> b_tau_Intercept   |  b_delta_Intercept | -0.82 | [-0.83, -0.81] | 1.94e+10 | < .001***

## What if we standardize the RRi interval? Would that reduce the correlation
## between model parameters without sacrificing information? Let's try...


# Model 3, standardization and priors -------------------------------------

## Standardization for each subject's RRi data
std_params <- sim_data[, list(mean_rri = mean(rri_hat), sd_rri = sd(rri_hat))]
sim_data[, rri_std := (rri_hat - std_params$mean_rri)/std_params$sd_rri][]

## Lets see how the standardize RRi values change
ggplot(sim_data, aes(time, rri_std, group = as.factor(id))) +
  facet_grid(~ id) +
  geom_line() +
  scale_y_continuous(expand = c(0.5,0), breaks = -4:4) +
  theme_linedraw()


## Changing priors
m_priors_2 <- 
  c(
    prior(normal(0, 1), nlpar = alpha), 
    prior(normal(-1, 1), nlpar = beta, ub = 0),
    prior(normal(0.8, 0.2), nlpar = c, lb = 0),
    prior(normal(-2, 1), nlpar = lambda, ub = 0),
    prior(normal(-2, 1), nlpar = phi, ub = 0),
    prior(normal(5, 0.5), nlpar = tau, lb = 0),
    prior(normal(5, 0.5), nlpar = delta, lb = 0),
    prior(student_t(3, 0, 50), class = sigma, lb = 0)
  )

brm_model_2 <- bf(
  formula = rri_std ~ alpha +
    (beta / (1 + exp(lambda * (time - tau)))) +
    ((-beta * c) / (1 + exp(phi * (time - tau - delta)))),
  alpha + beta + c + lambda + phi + tau + delta ~ 1,
  nl = TRUE
)

m_3 <- brm(
  formula = brm_model_2,
  data = sim_data,
  prior = m_priors_2,
  family = gaussian(),
  cores = 4, chains = 4
)

## Time running: 5.306 seconds (Total) ## Much faster!! Could be this the solution??

fixef(m_3)

#>                    Estimate  Est.Error       Q2.5      Q97.5
#> alpha_Intercept   0.6797224 0.11452947  0.4744033  0.9267617 
#> beta_Intercept   -2.1559805 0.24478073 -2.6943394 -1.7408590
#> c_Intercept       0.8209825 0.04916563  0.7242201  0.9187584
#> lambda_Intercept -1.3014973 0.33260568 -2.0963856 -0.7858623
#> phi_Intercept    -1.7338129 0.43542992 -2.7922418 -1.0603330
#> tau_Intercept     4.9658029 0.22382717  4.5126328  5.3812163
#> delta_Intercept   4.4665770 0.34662520  3.8058341  5.1517597

std_params[, mean_rri + 0.6797224 * sd_rri] 
#> alpha = 910.0223 
## Similar estimation than non-std model

std_params[, -2.1559805 * sd_rri] 
#> beta = -173.2112
## Smaller drop than estimated from previous model... Mmm...

conditional_effects(m_3) 
## Plot looks better than previous model, given that it seems to be capturing
## the underlying behaviour better than non-std model.

pp_check(m_3, ndraws = 100) ## Posterior predictive checks seems fine...

## Pairs plot to check between correlations
bayesplot::mcmc_pairs(x = m_3, 
                      regex_pars = "^b_", 
                      off_diag_fun = "hex")
## There's seem to be less curvy pairwise distributions. Could this be
## related to a decrease in correlation among model paramters? Let's
## check it...

as_draws_df(m_3, variable = "^b_", regex = TRUE) |> 
  correlation::correlation(method = "spearman") |> 
  subset(abs(rho) > .5)
## There seems to be high correlation (rho > .5) in:
#> b_alpha_Intercept |   b_beta_Intercept | -0.67 | [-0.69, -0.65] | 1.78e+10 | < .001***
#> b_alpha_Intercept |      b_c_Intercept | -0.76 | [-0.77, -0.74] | 1.87e+10 | < .001***
#> b_alpha_Intercept | b_lambda_Intercept |  0.59 | [ 0.57,  0.61] | 4.39e+09 | < .001***
#> b_beta_Intercept  | b_lambda_Intercept | -0.67 | [-0.69, -0.65] | 1.78e+10 | < .001***
#> b_tau_Intercept   |  b_delta_Intercept | -0.75 | [-0.76, -0.73] | 1.86e+10 | < .001***

## There seems to be a discrete reduction in correlation 
## among parameters, its an improvement at least. 

# Model 4, priors for fixef, std ------------------------------------------

brm_model_3 <- bf(
  formula = rri_std ~ alpha +
    (beta / (1 + exp(lambda * (time - tau)))) +
    ((-beta * c) / (1 + exp(phi * (time - tau - delta)))),
  alpha + beta + c + lambda + phi + tau + delta ~ 1 | id,
  nl = TRUE
)

m_4 <- brm(
  formula = brm_model_3,
  data = sim_data,
  prior = m_priors_2,
  family = gaussian(),
  cores = 4, chains = 4
)

## Run time: 306.339 seconds (Total) ## As expected, takes longer

print(m_4)
#> Multilevel Hyperparameters:
#> ~id (Number of levels: 5) 
#>                      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
#> sd(alpha_Intercept)      1.29      0.99     0.30     3.81 1.58        7       30
#> sd(beta_Intercept)       3.04      1.98     0.54     7.49 1.56        7      138
#> sd(c_Intercept)          0.71      0.62     0.09     2.16 1.78        6       79
#> sd(lambda_Intercept)     1.45      1.38     0.03     4.79 1.83        6       36
#> sd(phi_Intercept)        1.49      0.99     0.03     3.65 1.51        7       31
#> sd(tau_Intercept)        1.65      0.81     0.55     3.62 1.35        9       33
#> sd(delta_Intercept)      3.35      1.60     1.10     7.10 1.36        9       98
#> 
#> Regression Coefficients:
#>                  Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
#> alpha_Intercept      0.43      0.69    -1.26     1.44 1.44        8       36
#> beta_Intercept      -1.97      1.10    -3.85    -0.12 1.52        7       46
#> c_Intercept          0.82      0.16     0.44     1.08 1.11       24      306
#> lambda_Intercept    -1.85      0.68    -2.93    -0.30 1.25       12       48
#> phi_Intercept       -1.46      0.58    -2.80    -0.36 1.12     2148     1937
#> tau_Intercept        5.25      0.42     4.36     6.02 1.06       55     2592
#> delta_Intercept      4.56      0.54     3.48     5.59 1.04       73     1046
#> 
#> Further Distributional Parameters:
#>       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
#> sigma     0.31      0.01     0.29     0.33 1.00     4865     2989

## At a glance, poor estimation: low ESS, high Rhats and I think I
## may know why. Could this be related to the default priors chosen for the Ids?
## Let's try another configuration of priors for the Random effect of IDs

# Model 5, priors for ranef and fixef + std -------------------------------

m_priors_3 <- 
  c(
    ## Fix effects
    prior(normal(0, 1), nlpar = alpha), 
    prior(normal(-1, 1), nlpar = beta, ub = 0),
    prior(normal(0.8, 0.2), nlpar = c, lb = 0),
    prior(normal(-2, 1), nlpar = lambda, ub = 0),
    prior(normal(-2, 1), nlpar = phi, ub = 0),
    prior(normal(5, 0.5), nlpar = tau, lb = 0),
    prior(normal(5, 0.5), nlpar = delta, lb = 0),
    ## Random effects
    prior(normal(0, 1), nlpar = alpha, class = sd, lb = 0), 
    prior(normal(0, 1), nlpar = beta, class = sd, lb = 0),
    prior(normal(0, 0.2), nlpar = c, class = sd, lb = 0),
    prior(normal(0, 1), nlpar = lambda, class = sd, lb = 0),
    prior(normal(0, 1), nlpar = phi, class = sd, lb = 0),
    prior(normal(0, 0.5), nlpar = tau, class = sd, lb = 0),
    prior(normal(0, 0.5), nlpar = delta, class = sd, lb = 0),
    ## Sigma
    prior(student_t(3, 0, 50), class = sigma, lb = 0)
  )

m_5 <- brm(
  formula = brm_model_3,
  data = sim_data,
  prior = m_priors_3,
  family = gaussian(),
  cores = 4, chains = 4
)

## Run time: 114.741 seconds (Total)  ## It takes less time but maybe could be improved further!

print(m_5)
#> Multilevel Hyperparameters:
#> ~id (Number of levels: 5) 
#>                      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
#> sd(alpha_Intercept)      0.77      0.31     0.31     1.52 1.10       26       36 <== alpha
#> sd(beta_Intercept)       0.90      0.44     0.24     1.96 1.00     1634     1087
#> sd(c_Intercept)          0.27      0.18     0.09     0.68 1.52        7       34 <== c
#> sd(lambda_Intercept)     0.40      0.33     0.01     1.21 1.01     1608     2082
#> sd(phi_Intercept)        0.55      0.60     0.01     2.02 1.50        7       30 <== phi
#> sd(tau_Intercept)        1.04      0.21     0.70     1.53 1.00     2802     2580
#> sd(delta_Intercept)      0.96      0.34     0.31     1.63 1.00     1601     1200
#> 
#> Regression Coefficients:
#>                  Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
#> alpha_Intercept      0.71      0.40    -0.13     1.41 1.20       15       87 <== alpha again
#> beta_Intercept      -3.02      0.48    -3.87    -1.95 1.01     2177     2418
#> c_Intercept          0.82      0.14     0.45     1.02 1.26       12       33 <== c again
#> lambda_Intercept    -2.33      0.30    -2.97    -1.77 1.00     3151     2113
#> phi_Intercept       -1.53      0.36    -2.31    -0.66 1.16     2121       37 <== phi again
#> tau_Intercept        5.17      0.34     4.50     5.86 1.00     2180     2599
#> delta_Intercept      3.56      0.48     2.66     4.51 1.00     1742     1312

## At first there's seems to be only a problem in regard to alpha, c and phi parameters. 
## Maybe refining the priors on the SDs could resolve this issue? Let's check it!

conditional_effects(m_5) ## Wide CI, natural since we are taking into account the ID SD

p_m5 <- predict(m_5)
p_m5 <- cbind(p_m5, sim_data)

un_std <- function(i) {
  std_params$mean_rri + std_params$sd_rri * i
}

ggplot(p_m5, aes(time, group = id)) +
  facet_grid(~id) +
  geom_line(aes(y = rri_true), col = "red") +
  geom_line(aes(y = Estimate |> un_std()), col = "blue") +
  theme_light()

shinystan::launch_shinystan(m_5)
## Seems to be bimodality in posterior SD on c and phi, not on alpha.
## Potentially choosing a smaller sigma in those paramters SD could help

# Model 6, same as M5 but more tight priors on SDs -------------------------

m_priors_4 <- 
  c(
    ## Fix effects
    prior(normal(0, 1), nlpar = alpha), 
    prior(normal(-1, 1), nlpar = beta, ub = 0),
    prior(normal(0.8, 0.2), nlpar = c, lb = 0),
    prior(normal(-2, 1), nlpar = lambda, ub = 0),
    prior(normal(-2, 1), nlpar = phi, ub = 0),
    prior(normal(5, 0.5), nlpar = tau, lb = 0),
    prior(normal(5, 0.5), nlpar = delta, lb = 0),
    ## Random effects
    prior(normal(0, 0.5), nlpar = alpha, class = sd, lb = 0),    ## <= Less sigma here, ...
    prior(normal(0, 1), nlpar = beta, class = sd, lb = 0),
    prior(normal(0, 0.5), nlpar = c, class = sd, lb = 0),        ## <= Increasing sigma here ...
    prior(normal(0, 0.5), nlpar = lambda, class = sd, lb = 0), ## Changing this too for symetry in rate parameters
    prior(normal(0, 0.5), nlpar = phi, class = sd, lb = 0),    ## <= Less sigma here
    prior(normal(0, 0.5), nlpar = tau, class = sd, lb = 0), 
    prior(normal(0, 0.5), nlpar = delta, class = sd, lb = 0),
    ## Sigma
    prior(student_t(3, 0, 50), class = sigma, lb = 0)
  )

## I'm not trying with student_t prior given that the sd value can skyrocket in any
## given moment, even for a tight sd, so maybe as a plan B in case this doesn't work


## Fingers crossed!!
m_6 <- brm(
  formula = brm_model_3,
  data = sim_data,
  prior = m_priors_4,
  family = gaussian(),
  cores = 4, chains = 4
)

## Run time: 204.837 seconds (Total) ## Def not an improvement :c

print(m_6) ## Okay, this is worse!

conditional_effects(m_6) ## Even wider CI, this is not good...

shinystan::launch_shinystan(m_6)
## The bimodality seen before now is even clearer. It seems that the divergence
## occurs with c parameter, which seems to be reaching SD close to 1 when the
## predicted c is less than 0.5, which is not much realistic given the simulation
## parameters, so now im going setting its SD upper bound to 0.5, where it seems
## to be ocurring the convergence problem.


# EFFIN MODEL 7

m_priors_5 <- 
  c(
    ## Fix effects
    prior(normal(0, 1), nlpar = alpha), 
    prior(normal(-1, 1), nlpar = beta, ub = 0),
    prior(normal(1, 0.2), nlpar = c, lb = 0),
    prior(normal(-2, 0.5), nlpar = lambda, ub = 0),
    prior(normal(-2, 0.5), nlpar = phi, ub = 0),
    prior(normal(5, 0.5), nlpar = tau, lb = 0),
    prior(normal(5, 0.5), nlpar = delta, lb = 0),
    ## Random effects
    prior(normal(0, 0.5), nlpar = alpha, class = sd, lb = 0),  
    prior(normal(0, 0.5), nlpar = beta, class = sd, lb = 0),
    prior(normal(0, 0.2), nlpar = c, class = sd, lb = 0, ub = .5),      
    prior(normal(0, 0.2), nlpar = lambda, class = sd, lb = 0), 
    prior(normal(0, 0.2), nlpar = phi, class = sd, lb = 0),    
    prior(normal(0, 0.2), nlpar = tau, class = sd, lb = 0), 
    prior(normal(0, 0.2), nlpar = delta, class = sd, lb = 0),
    ## Sigma
    prior(student_t(3, 0, 3), class = sigma, lb = 0)
  )


## CMON MOTHERFUCHER!!
m_7 <- brm(
  formula = brm_model_3,
  data = sim_data,
  prior = m_priors_5,
  family = gaussian(),
  cores = 4, chains = 4
)

## Run time: 77.334 seconds (Total). ## This is it!

print(m_7)

conditional_effects(m_7)

p_m7 <- predict(m_7)
p_m7 <- cbind(p_m7, sim_data)

un_std <- function(i) {
  std_params$mean_rri + std_params$sd_rri * i
}

ggplot(p_m7, aes(time, group = id)) +
  facet_grid(~id) +
  geom_line(aes(y = rri_true), col = "red") +
  geom_line(aes(y = Estimate |> un_std()), col = "blue") +
  theme_light()
## There seems to be some systematic error in the estimation of
## the curves. specifically around alpha, beta and c.

shinystan::launch_shinystan(m_7)
## Looks better, it seems that they are not divergent 
## trasitions and the chains are mixing well. However,
## when we standardized the RRi intervals, we use the 
## global mean and sd, not the subject-specific mean and
## sd. That could be a good solution to improve even more
## the convergence of the chains, given that all signal
## data would be centered around their specific mean, and
## in other terms, 0.


# Model 8, ranef and fixef priors, subject-wise std -----------------------

sim_data[, rri_mean := mean(rri_hat), id]
sim_data[, rri_sd := sd(rri_hat), id]
sim_data[, rri_std := (rri_hat - rri_mean) / rri_sd, id]

ggplot(sim_data, aes(time, rri_std, group = 1)) +
  facet_grid(~ id) +
  geom_line()
## Now everyone are around the same values. This should improve
## model convergence. Fingers crossed.


## This should be better!
m_8 <- brm(
  formula = brm_model_3,
  data = sim_data,
  prior = m_priors_5,
  family = gaussian(),
  cores = 4, chains = 4
)

## Run time: 55.854 seconds (Total) ## Much better!!!

print(m_8)
#> Multilevel Hyperparameters:
#> ~id (Number of levels: 5) 
#>                      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
#> sd(alpha_Intercept)      0.48      0.17     0.25     0.93 1.00     2898     2603
#> sd(beta_Intercept)       0.50      0.28     0.04     1.13 1.01      705     1433 ## <= check this
#> sd(c_Intercept)          0.19      0.07     0.09     0.35 1.00     2644     2408
#> sd(lambda_Intercept)     0.25      0.15     0.01     0.55 1.00     1156     1780
#> sd(phi_Intercept)        0.18      0.12     0.01     0.46 1.00     1766     1808
#> sd(tau_Intercept)        0.71      0.09     0.55     0.92 1.00     3556     2747
#> sd(delta_Intercept)      0.37      0.17     0.04     0.69 1.01      715     1111 ## <= check this
#> 
#> Regression Coefficients:
#>                  Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
#> alpha_Intercept      0.82      0.22     0.35     1.26 1.00     1805     2149
#> beta_Intercept      -3.71      0.39    -4.43    -2.85 1.01      891     1993 ## <= check this
#> c_Intercept          0.89      0.08     0.74     1.06 1.00     1380     1822
#> lambda_Intercept    -2.35      0.24    -2.82    -1.89 1.00     2578     2649
#> phi_Intercept       -1.65      0.21    -2.08    -1.28 1.00     2169     3164
#> tau_Intercept        5.21      0.27     4.69     5.76 1.00     1802     2402
#> delta_Intercept      2.92      0.31     2.36     3.58 1.01      806     1773 ## <= check this
#> 
#> Further Distributional Parameters:
#>       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
#> sigma     0.39      0.01     0.36     0.41 1.00     6325     2741

shinystan::launch_shinystan(m_7)
## Seems there's not an evident problem with chains convergence
## or divergent transitions. Let's check if this whole procedure
## change with more samples
